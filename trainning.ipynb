{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Processing images: 100%|███████████████████| 5000/5000 [00:18<00:00, 268.75it/s]\n"
     ]
    }
   ],
   "source": [
    "!python /home/lucky/obj_det/vjt/data_preprocessing.py \\\n",
    "  --annotations /home/lucky/obj_det/vjt/annotations/instances_val2017.json \\\n",
    "  --images /home/lucky/obj_det/vjt/dataset/val2017 \\\n",
    "  --output /home/lucky/obj_det/vjt/dataset/data \\\n",
    "  --max-images 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login 1adedc7f69090be4cfd442f650c4daa364c1d0b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dca0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjhariaprabhat19\u001b[0m (\u001b[33mjhariaprabhat19-indian-institute-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/yuvraj/obj_det/vjt/wandb/run-20250416_015203-9jced4by\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzany-feather-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jhariaprabhat19-indian-institute-of-science/segmentation-training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jhariaprabhat19-indian-institute-of-science/segmentation-training/runs/9jced4by\u001b[0m\n",
      "/home/yuvraj/miniconda3/envs/seg-env/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model     | DeepLabV3Plus          | 25.4 M | train\n",
      "1 | loss_fn   | CrossEntropyLoss       | 0      | train\n",
      "2 | train_iou | MulticlassJaccardIndex | 0      | train\n",
      "3 | val_iou   | MulticlassJaccardIndex | 0      | train\n",
      "-------------------------------------------------------------\n",
      "25.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.4 M    Total params\n",
      "101.658   Total estimated model params size (MB)\n",
      "386       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0: 100%|████████████████████| 313/313 [02:30<00:00,  2.08it/s, v_num=d4by]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                  | 1/63 [00:00<00:10,  5.84it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                  | 2/63 [00:00<00:11,  5.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                  | 3/63 [00:00<00:11,  5.34it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█▏                 | 4/63 [00:00<00:11,  5.29it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▌                 | 5/63 [00:00<00:11,  5.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                 | 6/63 [00:01<00:10,  5.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|██                 | 7/63 [00:01<00:10,  5.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▍                | 8/63 [00:01<00:10,  5.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▋                | 9/63 [00:01<00:10,  5.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▊               | 10/63 [00:01<00:10,  5.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏              | 11/63 [00:02<00:10,  5.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▍              | 12/63 [00:02<00:09,  5.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▋              | 13/63 [00:02<00:09,  5.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████              | 14/63 [00:02<00:09,  5.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████▎             | 15/63 [00:02<00:09,  5.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▌             | 16/63 [00:03<00:09,  5.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▊             | 17/63 [00:03<00:08,  5.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|█████▏            | 18/63 [00:03<00:08,  5.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 19/63 [00:03<00:08,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▋            | 20/63 [00:03<00:08,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|██████            | 21/63 [00:04<00:08,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 22/63 [00:04<00:07,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▌           | 23/63 [00:04<00:07,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▊           | 24/63 [00:04<00:07,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▏          | 25/63 [00:04<00:07,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████▍          | 26/63 [00:05<00:07,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▋          | 27/63 [00:05<00:06,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████          | 28/63 [00:05<00:06,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████████▎         | 29/63 [00:05<00:06,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▌         | 30/63 [00:05<00:06,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|████████▊         | 31/63 [00:06<00:06,  5.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|█████████▏        | 32/63 [00:06<00:06,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████████▍        | 33/63 [00:06<00:05,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▋        | 34/63 [00:06<00:05,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|██████████        | 35/63 [00:06<00:05,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|██████████▎       | 36/63 [00:06<00:05,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|██████████▌       | 37/63 [00:07<00:05,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 38/63 [00:07<00:04,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|███████████▏      | 39/63 [00:07<00:04,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|███████████▍      | 40/63 [00:07<00:04,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 41/63 [00:07<00:04,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████████      | 42/63 [00:08<00:04,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████████▎     | 43/63 [00:08<00:03,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 44/63 [00:08<00:03,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████▊     | 45/63 [00:08<00:03,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████████▏    | 46/63 [00:08<00:03,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▍    | 47/63 [00:09<00:03,  5.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████████▋    | 48/63 [00:09<00:02,  5.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████████    | 49/63 [00:09<00:02,  5.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████████▎   | 50/63 [00:09<00:02,  5.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████████▌   | 51/63 [00:09<00:02,  5.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████▊   | 52/63 [00:10<00:02,  5.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|███████████████▏  | 53/63 [00:10<00:01,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████████▍  | 54/63 [00:10<00:01,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████████▋  | 55/63 [00:10<00:01,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|████████████████  | 56/63 [00:10<00:01,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▎ | 57/63 [00:11<00:01,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████████▌ | 58/63 [00:11<00:00,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████████▊ | 59/63 [00:11<00:00,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████▏| 60/63 [00:11<00:00,  5.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████████████▍| 61/63 [00:11<00:00,  5.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████████████▋| 62/63 [00:12<00:00,  5.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 63/63 [00:12<00:00,  5.16it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 313/313 [02:43<00:00,  1.92it/s, v_num=d4by, val_loss=0.837, va\u001b[A`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 313/313 [02:44<00:00,  1.90it/s, v_num=d4by, val_loss=0.837, va\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-summary.json 224B/224B (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 1.1KB/1.1KB (0.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading config.yaml 4.0KB/4.0KB (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 224B/224B (1.4s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 4.0KB/4.0KB (1.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading console lines 18-18 (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading console lines 18-18 (0.2s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train_dice ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step ▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val_iou ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train_dice 0.99787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val_iou 0.03827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 0.83738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mzany-feather-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jhariaprabhat19-indian-institute-of-science/segmentation-training/runs/9jced4by\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/jhariaprabhat19-indian-institute-of-science/segmentation-training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250416_015203-9jced4by/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python /home/lucky/obj_det/vjt/train.py \\\n",
    "  --data_path /home/lucky/obj_det/vjt/dataset \\\n",
    "  --epochs 100 \\\n",
    "  --lr 0.0001 \\\n",
    "  --num_classes 256 \\\n",
    "  --batch_size 16 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --img_size 512,512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051512e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python /home/lucky/obj_det/vjt/train.py \\\n",
    "  --data_path /home/lucky/obj_det/vjt/dataset \\\n",
    "  --epochs 100 \\\n",
    "  --lr 0.00001 \\\n",
    "  --num_classes 91 \\\n",
    "  --batch_size 16 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --img_size 512,512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae7d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mask values: 3\n",
      "Unique mask values: [ 0  1 35]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "mask = cv2.imread(str(\"/home/lucky/obj_det/vjt/dataset/masks/000000002532.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(f\"Unique mask values: {len(np.unique(mask))}\")\n",
    "print(f\"Unique mask values: {np.unique(mask)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from train import SegmentationModel \n",
    "\n",
    "config = {\n",
    "    \"num_classes\": 91,\n",
    "    \"class_weights\": [1.0] * 91,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"img_size\": (512, 512)\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "checkpoint_path = \"/home/lucky/LuckyML/checkpoints/epoch=53-step=16902.ckpt\"  # updated path with 'lucky'\n",
    "model = SegmentationModel.load_from_checkpoint(checkpoint_path, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fdaad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentationModel(\n",
       "  (model): DeepLabV3Plus(\n",
       "    (encoder): MixVisionTransformerEncoder(\n",
       "      (patch_embed1): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed2): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed3): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed4): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (block1): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.007)\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      (block2): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.020)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.033)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.040)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (block3): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.047)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.053)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.060)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.067)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.080)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "      (block4): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Identity()\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.087)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Identity()\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.093)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Identity()\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): DeepLabV3PlusDecoder(\n",
       "      (aspp): Sequential(\n",
       "        (0): ASPP(\n",
       "          (convs): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (1): ASPPSeparableConv(\n",
       "              (0): SeparableConv2d(\n",
       "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=512, bias=False)\n",
       "                (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (2): ASPPSeparableConv(\n",
       "              (0): SeparableConv2d(\n",
       "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=512, bias=False)\n",
       "                (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (3): ASPPSeparableConv(\n",
       "              (0): SeparableConv2d(\n",
       "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=512, bias=False)\n",
       "                (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (4): ASPPPooling(\n",
       "              (0): AdaptiveAvgPool2d(output_size=1)\n",
       "              (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (project): Sequential(\n",
       "            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SeparableConv2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "      (block1): Sequential(\n",
       "        (0): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): SeparableConv2d(\n",
       "          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
       "          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (segmentation_head): SegmentationHead(\n",
       "      (0): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "      (2): Activation(\n",
       "        (activation): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (train_iou): MulticlassJaccardIndex()\n",
       "  (val_iou): MulticlassJaccardIndex()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()  # if using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dd605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"/home/lucky/LuckyML/vjproject/vj_project/data/val2017/000000001532.jpg\")\n",
    "mask = cv2.imread(str(\"/home/lucky/LuckyML/vjproject/vj_project/data/masks/000000001532.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Resize and normalize (same as validation transform)\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "transformed = val_transform(image=img)\n",
    "input_tensor = transformed[\"image\"].unsqueeze(0).cuda()  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    prediction = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
    "    print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
